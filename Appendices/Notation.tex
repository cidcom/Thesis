%!TEX root = /Users/jakubkonka/Thesis/Thesis.tex
\chapter{Mathematical Notation and Preliminaries} % (fold)
\label{cha:notation}

\minitoc
\vspace{10mm}

This chapter, firstly, introduces mathematical notation used in this thesis. It then provides an overview of the more important mathematical concepts necessary to understand the work reported in this thesis.

\section{Notation} % (fold)
\label{sec:notation_notation}
Following the standard notation used in real analysis literature, we denote by $\mathbb{R}$ the set of all real numbers. An open subset of $\mathbb{R}$ is denoted by $(a,b)\subset \mathbb{R}$ such that $a < b$ and $a,b\in\mathbb{R}$. Similarly, $[a,b]\subset\mathbb{R}$ denotes a closed subset of $\mathbb{R}$, $(a,b]$ a half-open (from the left) subset, and $[a,b)$ a half-open (from the right) subset. The set of all positive (negative) real numbers, however, is denoted by $\mathbb{R}_+$ ($\mathbb{R}_-$).
% section notation (end)

\section{Set Theory} % (fold)
\label{sec:set_theory_notation}
Let $f: X\to Y$ be a function mapping set $X$ into $Y$.
\begin{thm}[Inverse of a Function]
\label{thm:inverse_of_a_function_notation}
The function $f:X\to Y$ has an inverse $f^{-1}: Y\to X$ if and only if $f$ is one-to-one and onto.
\end{thm}
\begin{proof}
Suppose $f$ has an inverse $f^{-1}$. Since $f^{-1}$ is a function, then for all $y\in Y$, there exists $x\in X$ such that $f^{-1}(y) = x$. Hence, $f$ is onto. Suppose there exist $x,x'\in X$ and $y\in Y$ such that $f(x) = y$ and $f(x') = y$. Then, $x = f^{-1}(y)$ and $x' = f^{-1}(y)$. But $f^{-1}$ is a function; hence, $x = x'$ and $f$ is one-to-one.

Conversely, suppose $f$ is one-to-one and onto. Let $f^{-1}: Y\to X$ so that for all $y\in Y$, there exists $x\in X$ such that $f^{-1}(y) = x$. Since $f$ is onto, for all $y\in Y$, there exists $x\in X$ such that $f(x) = y$. Furthermore, since $f^{-1}(y) = x$ for all $y\in Y$ by definition, then $f^{-1}(f(x)) = x$. Since $f$ is one-to-one, for all $x,x'\in X$, $f(x) = y$ and $f(x') = y$ implies $x = x'$. Since $f^{-1}(f(x)) = x$ by the previous assertion, then $f^{-1}(f(x)) = f^{-1}(f(x'))$. Hence, $f^{-1}$ is an inverse of $f$.
\end{proof}

Let $f$ be an increasing function. That is, for all $x,y\in X$ such that $x < y$, it follows that $f(x) < f(y)$.
\begin{corollary}
\label{cor:increasing_invertible_notation}
If $f$ is increasing, then it is invertible.
\end{corollary}
\begin{proof}
Every increasing function is one-to-one and onto.
\end{proof}
% subsection set_theory_notation (end)

\section{Probability Theory and Statistics} % (fold)
\label{sec:probability_notation}
Let $X$ denote an (absolutely-) continuous random variable (r.v.) with the support $[a, b]\subset\mathbb{R}$. By $F_{X}$ we mean a cumulative distribution function of the $X$ r.v.; therefore, for any $x\in\mathbb{R}$, $F_{X}(x) = P\{X \le x\}$, where $P\{X\le x\}$ denotes the probability of the event such that $X\le x$. If $F_{X}$ admits a density function, it shall be denoted by $f_{X} = \frac{d}{dx}F_{X}$. If it is clear from the context which variable is considered random, we shall drop the subscript; that is, $F_{X}= F$.

The expected value of $X$, denoted by $E[X]$, is defined as $E[X] = \int_{-\infty}^{\infty} xdF(x)$. Similarly, if $u$ is a function of $X$, then the expected value of $u(X)$ is defined as $E[u(X)] = \int_{-\infty}^{\infty} u(x)dF(x)$.

Let $X_1, \ldots, X_n$ be independent continuous r.v.s with distribution function $F$ and density function $f= \frac{d}{dx}F$. If we let $X_{i:n}$ denote the $i$th smallest of these r.v.s, then $X_{1:n}, \ldots,X_{n:n}$ are called the \emph{order statistics} \cite{Arnold08,David03}. In the event that the r.v.s are independently and identically distributed (i.i.d.), the distribution of $X_{i:n}$ is
\begin{equation}
	\label{eq:iid_cdf_notation}
	F_{X_{i:n}}(x) = \sum_{k=i}^{n} \binom{n}{k} (F(x))^k (1-F(x))^{n-k},
\end{equation}
while the density of $X_{i:n}$ can be obtained by differentiating Equation~\eqref{eq:iid_cdf_notation} with respect to $x$ \cite{Ross10}. Hence,
\begin{equation}
	\label{eq:iid_pdf_notation}
	f_{X_{i:n}}(x) = \frac{n!}{(n-i)!(i-1)!} f(x) (F(x))^{i-1} (1-F(x))^{n-i}.
\end{equation}

Let $X_1,\ldots,X_n$ be i.i.d.~r.v.s with finite mean $\mu$. Let
\begin{equation*}
  \bar{X}(n) = \frac{\sum_{i=1}^n X_i}{n}.
\end{equation*}
Then, for sufficiently large $n$, $\bar{X}(n)$ provides a reasonable approximation of $\mu$ \cite{LawChapter42007}. This result is known as the Strong Law of Large Numbers,
\begin{thm}[Strong Law of Large Numbers]
$\bar{X}(n)\rightarrow\mu$ with probability $1$ as $n\rightarrow\infty$.
\end{thm}
\begin{proof}
For proof of this theorem, we refer the Reader to Chung's ``A Course in Probability Theory'' \cite{Chung2001}.
\end{proof}
% subsection probability_notation (end)

\section{Game Theory} % (fold)
\label{sec:theory_of_games_notation}

\subsection{Static Games with Incomplete Information} % (fold)
\label{sub:static_games_with_incomplete_information_notation}
Let $\Gamma^B = [N, \{S_i\}, \{u_i\},\Theta,F]$ be a \emph{Bayesian game with incomplete information}. Formally, in this type of games, each player $i\in N$ has a utility function $u_i(s_i, s_{-i}, \theta_i)$, where $s_i\in S_i$ denotes player $i$'s action, $s_{-i}\in S_{-i} = \vartimes_{j\neq i}S_j$ denotes actions of all other players different from $i$, and $\theta_i\in\Theta_i$ represents the type of player $i$. Letting $\Theta = \vartimes_{i\in N} \Theta_i$, the joint probability distribution of the $\theta\in\Theta$ is given by $F(\theta)$, which is assumed to be common knowledge among the players. For a more in-depth treatment of the theory of games see for example \cite{Myerson97, Gibbons92, MicroTheory}.

In game $\Gamma^B$, a \emph{pure strategy} for player $i$ is a function $\psi_i: \Theta_i\to S_i$, where for each type $\theta_i\in \Theta_i$, $\psi_i(\theta_i)$ specifies the action from the feasible set $S_i$ that type $\theta_i$ would choose. Therefore, player $i$'s pure strategy set $\Psi_i$ is the set of all such functions.

Player $i$'s \emph{expected utility} given a profile of pure strategies $(\psi_1,\ldots,\psi_{|N|})$ is given by
\begin{equation}
	\label{eq:def_exp_utility_notation}
	\tilde{u}_i(\psi_1,\ldots,\psi_{|N|}) = E[u_i(\psi_1(\theta_1),\ldots,\psi_{|N|}(\theta_{|N|}),\theta_i)],
\end{equation}
where the expectation is taken over the realisations of the players' types, $\theta\in\Theta$. Now, in game $\Gamma^B$, a strategy profile $(\psi_1^*,\ldots,\psi_{|N|}^*)$ is a \emph{pure-strategy Bayesian Nash equilibrium} if it constitutes a Nash equilibrium of game $\Gamma^N = [N, \{\Psi_i\},\{\tilde{u}_i\}]$; that is, if for each player $i\in N$,
\begin{equation}
	\label{eq:def_bayesian_nash_eq_notation}
	\tilde{u}_i(\psi^*_i,\psi^*_{-i}) \ge \tilde{u}_i(\psi_i,\psi^*_{-i})
\end{equation}
for all $\psi_i\in\Psi_i$, where $\tilde{u}_i(\psi_i,\psi_{-i})$ is defined as in Equation~\eqref{eq:def_exp_utility_notation}.

Alternatively, a strategy profile $(\psi_1^*,\ldots,\psi_{|N|}^*)$ constitutes a pure-strategy Bayesian Nash equilibrium in game $\Gamma^B$ if and only if, for all $i\in N$ and all $\hat{\theta}_i\in\Theta_i$ occurring with positive probability
\begin{equation}
	\label{eq:prop_bayesian_nash_eq_notation}
	E[u_i(\psi^*_i(\hat{\theta}_i),\psi^*_{-i}(\theta_{-i}),\hat{\theta}_i)\mid\hat{\theta}_i] \ge
	E[u_i(s'_i,\psi^*_{-i}(\theta_{-i}),\hat{\theta}_i)\mid\hat{\theta}_i]
\end{equation}
for all $s'_i\in S_i$, where the expectation is taken over realisations of the other players' types, $\theta_{-i}$, conditional on player $i$'s realisation of his type, $\hat{\theta}_i$. In other words, each type of player $i$ can be thought of as a separate player who maximises his payoff given his conditional probability distribution over the strategy choices of his rivals.
% subsubsection static_games_with_incomplete_information_notation (end)

\subsection{Mechanism Design Theory} % (fold)
\label{sub:mechanism_design_theory_notation}
In economics, a system where economic transactions take place and goods are allocated is called an \emph{allocation mechanism}; for example, an auction is an allocation mechanism. This section summarises the most important concepts of mechanism design theory. For a more in-depth treatment, see for example \cite{MechDesign07,Krishna10,HarrisRaviv1981,HarrisTownsend1975,Myerson1979,Myerson1981}.

Let $(\mathcal{B},\pi,\mu)$ be a mechanism representing any given auction. In this notation: $\mathcal{B}$ is a set of all possible bids; $\pi: \mathcal{B}\to \Delta$ is an \emph{allocation rule}, where $\Delta$ is a set of all probability distributions over the set of bidders $N$; and $\mu:\mathcal{B}\to\mathbb{R}^n$ is a \emph{payment rule} where $n = |N|$. The allocation rule quantifies as a function of all $n$ bids the probability that bidder $i$ receives the good. The payment rule determines as a function of all $n$ bids the expected payment that bidder $i$ must make. For example, if $\mathbf{b}=(b_i,b_{-i})$ is the vector of all bids submitted to the mechanism, the probability that bidder $i$ receives the good is $\pi_i(\mathbf{b})$, while the expected payment is $\mu_i(\mathbf{b})$.

Every mechanism can be viewed as a game with incomplete information between $n$ bidders. For each bidder $i$ we let $b_i(\cdot): \Theta_i \to\mathcal{B}_i$ be the pure strategy where as before $\Theta_i$ is the set of all possible valuations of bidder $i$. The \emph{equilibrium} of the mechanism is hence defined as an $n$-tuple of strategies $(b_i(\cdot),b_{-i}(\cdot))$ if for all $i$ and for all $\theta_i\in\Theta_i$, $b_i(\theta_i)$ maximises bidder $i$'s expected payoff.

If $\mathcal{B}_i = \Theta_i$ for all $i$, then the mechanism becomes the so-called \emph{direct mechanism}. In a direct mechanism, bidders are effectively submitting their valuations rather than bids to the mechanism. In general, direct mechanisms tend to be smaller and simpler than generic mechanisms, and therefore are easier to analyse while still being able to model the scenario accurately. Formally, a direct mechanism is defined as a tuple $(\mathbf{Q},\mathbf{M})$ with an allocation rule defined as $\mathbf{Q}:\nobreak\Theta\to\Delta$, and a payment rule defined as $\mathbf{M}:\nobreak\Theta\to\mathbb{R}^n$. Note that in direct mechanism bidders' valuations are directly used to determine the outcome of the mechanism.

A direct mechanism $(\mathbf{Q},\mathbf{M})$ is said to satisfy \emph{incentive compatibility} (IC) constraint if for all $i\in N$, for all $\theta_i\in\Theta_i$, and for all $\hat{\theta}_i\in\Theta_i$,
\begin{equation*}
  \tilde{\tilde{u}}_i(\theta_i) = q_i(\theta_i)\theta_i - m_i(\theta_i)\ge q_i(\hat{\theta}_i)\theta_i - m_i(\hat{\theta}_i),
\end{equation*}
where
\begin{equation*}
  q_i(\hat{\theta}_i) = E[Q_i(\hat{\theta}_i,\theta_{-i})],
\end{equation*}
and
\begin{equation*}
  m_i(\hat{\theta}_i) = E[M_i(\hat{\theta}_i, \theta_{-i})].
\end{equation*}
In both cases, the expectation is taken over the realisations of all but player $i$ types, $\theta_{-i}\in\Theta_{-i}$.

A direct mechanism $(\mathbf{Q}, \mathbf{M})$ is said to satisfy \emph{individual rationality} (IR) constraint if for all $i\in N$, and for all $\theta_i\in\Theta_i$,
\begin{equation*}
  \tilde{\tilde{u}}_i(\theta_i)\ge 0.
\end{equation*}

In this thesis, we also make use of the very powerful Revelation Principle theorem due to Myerson which states the link between any generic mechanism and a direct mechanism~\cite{Myerson1979, Krishna10}:
\begin{thm}[Revelation Principle]
\label{thm:revelation_principle_notation}
Given a mechanism and an equilibrium for that mechanism, there exists a direct mechanism in which (1) it is an equilibrium for each buyer to report his or her value truthfully and (2) the outcomes are the same as in the given equilibrium of the original mechanism.
\end{thm}
\begin{proof}
For proof of this theorem, we refer the Reader to Krishna's ``Auction Theory'' \cite{Krishna10}.
\end{proof}
% subsubsection mechanism_design_theory_notation (end)
% subsection theory_of_games (end)

\section{Optimisation Theory} % (fold)
\label{sec:optimisation_theory_notation}
The following theorem on nonlinear constrained optimisation is also be used in this thesis.
\begin{thm}[Karush-Kuhn-Tucker Conditions]
Let $f:\mathbb{R}^n\to\mathbb{R}$ be a concave function, $g_i:\mathbb{R}^n\to\mathbb{R}$ be convex functions for $i=1,\ldots,m$, and $h_j:\mathbb{R}^n\to\mathbb{R}$ be affine functions for $j=1,\ldots,l$. Then $\mathbf{x}^*\in\mathbb{R}^n$ is an optimal point for the following optimisation problem:
\begin{equation*}
	\left\{
	\begin{array}{rl}
		\max &f(x_1,\ldots,x_n)\\
		\text{subject to} &g_1(x_1,\ldots,x_n)\le 0\\
		& \vdots\\
		&g_m(x_1,\ldots,x_n)\le 0\\
		&h_1(x_1,\ldots,x_n) = 0\\
		& \vdots\\
		&h_l(x_1,\ldots,x_n) = 0
	\end{array}
	\right.
\end{equation*}
if and only if there exist unique multipliers $\bm{\lambda}=(\lambda_1,\ldots,\lambda_m)\ge 0$ and $\bm{\mu}=(\mu_1,\ldots,\mu_l)\in\mathbb{R}$ such that the Lagrangian
\begin{equation*}
	L(\mathbf{x},\bm{\lambda},\bm{\mu}) = f(\mathbf{x}) - \sum_{i=1}^m\lambda_i g_i(\mathbf{x}) - \sum_{j=1}^l\mu_j h_j(\mathbf{x})
\end{equation*}
is stationary at $(\mathbf{x}^*,\bm{\lambda},\bm{\mu})$, that is,
\begin{equation*}
	\nabla L(\mathbf{x}^*,\bm{\lambda},\bm{\mu}) = \nabla f(\mathbf{x}^*) - \sum_{i=1}^m\lambda_i \nabla g_i(\mathbf{x}^*) - \sum_{j=1}^l\mu_j \nabla h_j(\mathbf{x}^*) = \mathbf{0},
\end{equation*}
and satisfies the complementary slackness conditions
\begin{equation*}
	\lambda_i g_i(\mathbf{x}^*)=0 \quad\text{for } i=1,\ldots,m.
\end{equation*}
\end{thm}
\begin{proof}
For the proof of this theorem, we refer the Reader to Carter's ``Foundations of Mathematical Economics'' \cite{Carter2001}.
\end{proof}
% section optimization_theory_notation (end)

% section preliminaries (end)

% chapter notation (end)